####################################
# MySQL -> HDFS connector common
####################################

mr.job.max.mappers=1
taskexecutor.threadpool.size=1
taskretry.threadpool.coresize=1
taskretry.threadpool.maxsize=1

# Source properties
source.class=gobblin.source.extractor.extract.jdbc.MysqlSource
source.max.number.of.partitions=1
source.conn.driver=com.mysql.jdbc.Driver
source.conn.timeout=500000
source.conn.port=3306

#Timezone table http://joda-time.sourceforge.net/timezones.html
source.timezone=America/Los_Angeles

source.querybased.is.compression.enabled=true

#Only applicable for source.querybased.extract.type=snapshot
source.querybased.low.watermark.backup.secs=0
# Start value is required for more than one partition
source.querybased.start.value=19700101000000
source.querybased.watermark.type=timestamp
source.max.number.of.partitions=1
source.querybased.partition.interval=1

# file name of output data
extract.namespace=${source.querybased.schema}

# Converter properties - Record from source will be processed by the below series of converters
converter.classes=gobblin.converter.avro.JsonIntermediateToAvroConverter
converter.avro.timestamp.format=yyyy-MM-dd HH:mm:ss'.0'
converter.avro.date.format=yyyy-MM-dd
converter.avro.time.format=HH:mm:ss

qualitychecker.task.policies=gobblin.policies.count.RowCountPolicy
qualitychecker.task.policy.types=FAIL

writer.destination.type=HDFS
writer.output.format=AVRO
writer.file.path=${source.entity}

data.publisher.type=gobblin.publisher.BaseDataPublisher