config:
  prop1: foo
name: valid_dag_2
nodes:
- config:
    command: echo "task 2_1"
  name: task_2_1
  type: command
- config:
    k2: v2
  name: local_emb_2
  nodes:
  - config:
      command: echo "task 2a"
    name: task_2a
    type: command
  type: flow
- config:
    command: echo "task 2_2"
  dependsOn:
  - task_2_1
  name: task_2_2
  type: command
- config:
    p3: flow3_prop
  dependsOn:
  - task_2_1
  name: valid_dag_3
  nodes:
  - config:
      command: echo "task 3_1"
    name: task_3_1
    type: command
  - config:
      job.class: gobblin.data.management.retention.DatasetCleanerJob
      user.to.proxy: userToProxy
    dependsOn:
    - task_3_1
    name: task_3_2
    type: hadoopJava
  - config:
      class: com.linkedin.frame.offline.metrics.HdfsCompactionJob
      driver-memory: 2g
      execution-jar: lib/frame-metrics-compactor_2.11.jar
      executor-cores: 2
      num-executors: 6
      queue: default
    dependsOn:
    - task_3_2
    - task_3_4
    name: task_3_5
    type: spark
  - config:
      class: com.linkedin.relevance.datasetsSpecificAvro.app.AssertAggregateValues
      driver-memory: 1g
      execution-jar: lib/mymodule.jar
      executor-cores: 1
      num-executors: 2
      queue: default
    dependsOn:
    - task_3_3
    name: task_3_4
    type: spark
  - config:
      command: echo "task 3_3"
    name: task_3_3
    type: command
  type: flow
- dependsOn:
  - valid_dag_4
  - valid_dag_5
  - local_emb_2
  name: _end_
  type: noop
- config:
    k5: v5
  dependsOn:
  - task_2_2
  name: valid_dag_5
  nodes:
  - config:
      command: echo "task 5_1"
    name: task_5_1
    type: command
  - config:
      k6: v6
    dependsOn:
    - task_5_2
    - task_5_1
    name: valid_dag_6
    nodes:
    - config:
        command: echo "task 6_1"
      name: task_6_1
      type: command
    - config:
        command: echo "task 6_2"
      dependsOn:
      - task_6_1
      name: task_6_2
      type: command
    - config:
        command: echo "task 6_5"
      dependsOn:
      - task_6_2
      name: task_6_5
      type: command
    - config:
        command: echo "task 6_3"
      dependsOn:
      - task_6_2
      name: task_6_3
      type: command
    - config:
        command: echo "task 6_4"
      dependsOn:
      - task_6_3
      name: task_6_4
      type: command
    type: flow
  - config:
      command: echo "task 5_2"
    name: task_5_2
    type: command
  - config:
      command: echo "task 5_3"
    dependsOn:
    - valid_dag_6
    name: task_5_3
    type: command
  type: flow
- config:
    k4: v4
  dependsOn:
  - valid_dag_3
  name: valid_dag_4
  nodes:
  - config:
      command: echo "task 4_1"
    name: task_4_1
    type: command
  - config:
      class: gobblin.data.management.retention.SparkJobs
      driver-memory: 8g
      execution-jar: analyticsJob
      queue: default
    dependsOn:
    - task_4_1
    name: task_4_3
    type: spark
  - config:
      job.class: gobblin.data.management.retention.DatasetCleanerJob
    dependsOn:
    - task_4_1
    name: task_4_2
    type: hadoopJava
  type: flow
type: flow
